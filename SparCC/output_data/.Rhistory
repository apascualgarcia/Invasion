if(i == 1){ # the first level has as many block distances as clusters
Nblocks=Nclus[i]
}else{ # and half off diagonal. The remainder clusters only have off diagonal blocks
Nblocks=Nclus[i]/2
}
k=0
for(j in 1:Nblocks){
k=k+1 # this index will create a factor variable to identify the clusters
M=matrix(rnorm(size*size,mean=breaks[i],sd=stdv),size,size)
if(i == 1){ # The first level fills diagonal blocks
idx=j-1
col1=size*idx+1
row1=col1
clusInit=col1
}else{ # all remaining blocks are off diagonal
idx=2*j-1
col1=size*idx+1
row1=size*(idx-1)+1
clusInit=col1-size
}
col2=col1+size-1
row2=row1+size-1
clusEnd=col2
corrMat[row1:row2,col1:col2]=M
corrMat[col1:col2,row1:row2]=M
partMat[clusInit:clusEnd,i]=k
}
}
View(partMat)
Nperm0=99
setMethod="anosim"
for(i in 1:levels){ # for each level
if(setMethod=="anosim"){
AA=anosim(DistCor.dist, as.factor(partMat[,i]), permutations = Nperm0)
anosimSumm[i]=AA$statistic
anosimSig[i]=AA$signif
}else{
tmp.frame=as.data.frame(partMat[,i])
colnames(tmp.frame)="X"
AA=adonis2(DistCor.dist~X , tmp.frame, permutations = Nperm0)
anosimSumm[i]=AA$F[1]
anosimSig[i]=AA$`Pr(>F)`[1]
}
}
libary(vegan)
library(vegan)
for(i in 1:levels){ # for each level
if(setMethod=="anosim"){
AA=anosim(DistCor.dist, as.factor(partMat[,i]), permutations = Nperm0)
anosimSumm[i]=AA$statistic
anosimSig[i]=AA$signif
}else{
tmp.frame=as.data.frame(partMat[,i])
colnames(tmp.frame)="X"
AA=adonis2(DistCor.dist~X , tmp.frame, permutations = Nperm0)
anosimSumm[i]=AA$F[1]
anosimSig[i]=AA$`Pr(>F)`[1]
}
}
DistCor=sqrt(2*(1-corrMat))
as.dist(DistCor)-> DistCor.dist
attr(DistCor.dist, "method") <- "dist"
anosimSumm=matrix(NA,nrow=(length(distcuts)-1),ncol=1)
anosimSig=matrix(NA,nrow=(length(distcuts)-1),ncol=1) # Will not be printed, since there is plotCtrl below for that
anosimSumm=matrix(NA,nrow=levels,ncol=1)
anosimSig=matrix(NA,nrow=levels,ncol=1) # Will not be printed, since there is plotCtrl below for that
Nperm0=99
setMethod="anosim"
for(i in 1:levels){ # for each level
if(setMethod=="anosim"){
AA=anosim(DistCor.dist, as.factor(partMat[,i]), permutations = Nperm0)
anosimSumm[i]=AA$statistic
anosimSig[i]=AA$signif
}else{
tmp.frame=as.data.frame(partMat[,i])
colnames(tmp.frame)="X"
AA=adonis2(DistCor.dist~X , tmp.frame, permutations = Nperm0)
anosimSumm[i]=AA$F[1]
anosimSig[i]=AA$`Pr(>F)`[1]
}
}
plot(anosimSumm)
dev.off()
dev.off()
plot(anosimSumm)
library(ggmap)
library(mapproj)
time=seq(1:365)
a=1
b=1
N0=2
N_malt=N0*exp(b*time)
N_gomp=N0*exp(-b*(exp(a*time)-1))
plot(time,N_gomp)
N_gomp=N0*exp(-b*(exp(-a*time)))
plot(time,N_gomp)
time=seq(1:50)
a=1
b=1
N0=2
N_malt=N0*exp(b*time)
N_gomp=N0*exp(-b*(exp(-a*time)))
plot(time,N_gomp)
N0=200000
N_malt=N0*exp(b*time)
N_gomp=N0*exp(-b*(exp(-a*time)))
plot(time,N_gomp)
time=seq(1:50)
a=1
b=1
N0=200
N_malt=N0*exp(b*time)
N_gomp=N0*exp(-b*(exp(-a*time)))
plot(time,N_gomp)
points(time,N_gomp,type = "",pch="2",col="red")
points(time,N_malt,pch="2",col="red")
plot(time,N_gomp)
points(time,N_malt,pch="2",col="red")
plot(time,N_malt,pch="2",col="red")
plot(time,N_malt,pch=2,col="red")
plot(time,N_gomp)
N_gomp=N0*exp(ln(NI/N0)*(1-exp(b*time)))
N_gomp=N0*exp(log(NI/N0)*(1-exp(b*time)))
NI=20000
N_gomp=N0*exp(log(NI/N0)*(1-exp(b*time)))
plot(time,N_gomp)
N_gomp=N0*exp(log(NI/N0)*(1-exp(-b*time)))
plot(time,N_gomp)
points(time,N_malt,pch=2,col="red")
b=0.3
N_malt=N0*exp(b*time)
N_gomp=N0*exp(log(NI/N0)*(1-exp(-b*time)))
plot(time,N_gomp)
points(time,N_malt,pch=2,col="red")
a=0.3
b=0.05
N0=200
NI=20000
N_malt=N0*exp(b*time)
N_gomp=N0*exp(log(NI/N0)*(1-exp(-b*time)))
plot(time,N_gomp)
points(time,N_malt,pch=2,col="red")
b=0.1
N_malt=N0*exp(b*time)
points(time,N_malt,pch=2,col="red")
lm(log(N_gomp[1:20])
plot(time,N_gomp)
points(time,N_malt,pch=2,col="red")
lm(log(N_gomp[1:20]~time[1:20])
plot(time,N_gomp)
points(time,N_malt,pch=2,col="red")
lm(log(N_gomp[1:20]~time[1:20]))
lm(log(N_gomp[1:20])~time[1:20])
N0=2
N_malt=N0*exp(b*time)
N_gomp=N0*exp(log(NI/N0)*(1-exp(-b*time)))
lm(log(N_gomp[1:20])~time[1:20])
a=0.1
b=0.1
N_gomp=N0*exp(log(NI/N0)*(1-exp(-b*time)))
lm(log(N_gomp[1:20])~time[1:20])
N_malt=N0*exp(a*time)
plot(time,N_gomp)
points(time,N_malt,pch=2,col="red")
model=lm(log(N_gomp[1:20])~time[1:20]) # fit to an exponential
b=model$coefficients[1] # exponent for the Malthus model
time=seq(1:50) # Model 50 days
a=0.35 # exponent for the Gompertz model (no data)
N0=2 # Starting number of infections
NI=20000 # Expected number of infected cases
N_gomp=N0*exp(log(NI/N0)*(1-exp(-b*time))) # create the model
model=lm(log(N_gomp[1:20])~time[1:20]) # fit to an exponential
b=model$coefficients[1] # exponent for the Malthus model
c=model$coefficients[2] # ordinate
N_malt=exp(b*time+c)
plot(time,N_gomp)
points(time,N_malt,pch=2,col="red")
plot(time,N_gomp)
a=0.1 # exponent for the Gompertz model (no data)
N0=2 # Starting number of infections
NI=20000 # Expected number of infected cases
N_gomp=N0*exp(log(NI/N0)*(1-exp(-b*time))) # create the model
plot(time,N_gomp)
a=1 # exponent for the Gompertz model (no data)
N_gomp=N0*exp(log(NI/N0)*(1-exp(-b*time))) # create the model
plot(time,N_gomp)
a=1 # exponent for the Gompertz model (no data)
N0=2 # Starting number of infections
NI=20000 # Expected number of infected cases
N_gomp=N0*exp(log(NI/N0)*(1-exp(-b*time))) # create the model
a=0.1 # exponent for the Gompertz model (no data)
N0=2 # Starting number of infections
NI=20000 # Expected number of infected cases
N_gomp=N0*exp(log(NI/N0)*(1-exp(-a*time))) # create the model
plot(time,N_gomp)
b=model$coefficients[1] # exponent for the Malthus model
c=model$coefficients[2] # ordinate
N_malt=exp(b*time+c)
plot(time,N_gomp)
points(time,N_malt,pch=2,col="red")
N_malt=N0*exp(b*time+c)
points(time,N_malt,pch=2,col="red")
plot(time,N_gomp)
points(time,N_malt,pch=2,col="red")
model
b=model$coefficients[2] # exponent for the Malthus model
c=model$coefficients[1] # ordinate
N_malt=N0*exp(b*time+c)
plot(time,N_gomp)
points(time,N_malt,pch=2,col="red")
plot(time,Nmalt)
plot(time,N_malt)
N_malt=N0*exp(b*time)+exp(c)
plot(time,N_malt)
plot(time,N_gomp)
points(time,N_malt,pch=2,col="red")
model
o
model$coefficients[2]
source('~/.active-rstudio-document')
est=30 # days observed to estimate the model
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
NI=200000 # Expected number of infected cases
N_gomp=N0*exp(log(NI/N0)*(1-exp(-a*time))) # create the model
points(time,N_gomp,pch=3,col="green")
yaxis(Population)
yaxes(Population)
plot(time,N_gomp,ylab = "Population")
dd=cbind(N_gomp1,N_gomp2,N_malt)
NI1=20000 # Expected number of infected cases, first estimation
NI2=200000 # Expected number of infected cases, second estimation
est=10 # days observed to estimate a Malthusian model
N_gomp1=N0*exp(log(NI1/N0)*(1-exp(-a*time))) # create the model 1
model=lm(log(N_gomp[1:est])~time[1:est]) # fit to an exponential
N_gomp2=N0*exp(log(NI2/N0)*(1-exp(-a*time))) # create the model 1
b=model$coefficients[2] # exponent for the Malthus model
c=model$coefficients[1] # ordinate
N_malt=N0*exp(b*time)#+exp(c)
library(ggplot2)
ggplot(dd)+
geom_point()
dd=cbind(N_gomp1,N_gomp2,N_malt)
ggplot(dd)+
geom_point()
colnames(dd)=c("Gompertz low","Gompertz high","Malthus")
ggplot(dd)+
geom_point()
dd=as.data.frame(cbind(N_gomp1,N_gomp2,N_malt))
colnames(dd)=c("Gompertz low","Gompertz high","Malthus")
ggplot(dd)+
geom_point()
dd=as.data.frame(cbind(time,N_gomp1,N_gomp2,N_malt))
colnames(dd)=c("time (days)","Gompertz low","Gompertz high","Malthus")
ggplot(dd)+
geom_point(x=dd$`time (days)`,y=dd$`Gompertz low`)
ggplot(dd,aes(x=dd$`time (days)`,y=dd$`Gompertz low`))+
geom_point()
ggplot(dd,aes(x=dd$time,y=dd$low))+
geom_point()+
geom_point(dd,aes(x=dd$time,y=dd$high),)+
# Compare models
plot(time,N_gomp,ylab = "Population")
ggplot(dd,aes(x=dd$time,y=dd$low))+
geom_point()+
geom_point(dd,aes(x=dd$time,y=dd$high))
ggplot(dd,aes(x=dd$time,y=dd$low))+
geom_point()+
geom_point(aes(x=dd$time,y=dd$high))
dd.long=reshape2::melt(dd, id.var='time')
colnames(dd)=c("time","low","high","Malthus")
dd.long=reshape2::melt(dd, id.var='time')
head(dd.long)
dd=as.data.frame(cbind(time,N_gomp1,N_gomp2,N_malt))
colnames(dd)=c("time","Gompfertz low","Gompertz high","Malthus")
dd.long=reshape2::melt(dd, id.var='time')
dd.long=reshape2::melt(dd, id.var='time',variable="model")
ggplot(dd)+
geom_point()
ggplot(dd,aes(x=`Time (days)`,y=Population,col=Model))+
geom_point()
dd=as.data.frame(cbind(time,N_gomp1,N_gomp2,N_malt))
colnames(dd)=c("time","Gompfertz low","Gompertz high","Malthus")
dd.long=reshape2::melt(dd, id.var='time')
colnames(dd.long)=c("Time (days)","Model","Population")
ggplot(dd,aes(x=`Time (days)`,y=Population,col=Model))+
geom_point()
ggplot(dd,aes(x=Time (days),y=Population,col=Model))+
geom_point()
colnames(dd.long)=c("Time","Model","Population")
ggplot(dd,aes(x=Time,y=Population,col=Model))+
geom_point()
colnames(dd.long)=c("Time","Model","Population")
ggplot(dd,aes(x=Time,y=Population,col=Model))+
geom_point()
ggplot(dd.long,aes(x=Time,y=Population,col=Model))+
geom_point()
plot(time,N_gomp)
points(time,N_malt,pch=2,col="red")
points(time,N_gomp,pch=3,col="green")
points(time,N_gomp2,pch=3,col="green")
time=seq(1:50) # Model 50 days
a=0.1 # exponent for the Gompertz model (no data)
N0=2 # Starting number of infections
NI1=20000 # Expected number of infected cases, first estimation
NI2=200000 # Expected number of infected cases, second estimation
est=10 # days observed to estimate a Malthusian model
N_gomp1=N0*exp(log(NI1/N0)*(1-exp(-a*time))) # create the model 1
model=lm(log(N_gomp[1:est])~time[1:est]) # fit to an exponential
N_gomp2=N0*exp(log(NI2/N0)*(1-exp(-a*time))) # create the model 2
b=model$coefficients[2] # exponent for the Malthus model
c=model$coefficients[1] # ordinate
N_malt=N0*exp(b*time) # malthusian model
plot(time,N_gomp1)
points(time,N_malt,pch=2,col="red")
points(time,N_gomp2,pch=3,col="green")
clear all
clean all
clean
close()
library(ggplot2)
time=seq(1:50) # Model 50 days
a=0.1 # exponent for the Gompertz model (no data)
N0=2 # Starting number of infections
NI1=20000 # Expected number of infected cases, first estimation
NI2=200000 # Expected number of infected cases, second estimation
est=10 # days observed to estimate a Malthusian model
N_gomp1=N0*exp(log(NI1/N0)*(1-exp(-a*time))) # create the model 1
model=lm(log(N_gomp[1:est])~time[1:est]) # fit to an exponential
model
model$residuals
summary(model)
N_gomp2=N0*exp(log(NI2/N0)*(1-exp(-a*time))) # create the model 2
b=model$coefficients[2] # exponent for the Malthus model
c=model$coefficients[1] # ordinate
N_malt=N0*exp(b*time) # malthusian model
source('~/Dropbox/alberto.pascual/Dropbox/Research/Programs/microvirus/gompertz_vs_malthus.R')
plot(time,N_gomp1)
points(time,N_malt,pch=2,col="red")
points(time,N_gomp2,pch=3,col="green")
summary(model)
plot(time,N_gomp1)
points(time,N_malt,pch=2,col="red")
points(time,N_gomp2,pch=3,col="green")
source('~/Dropbox/alberto.pascual/Dropbox/Research/Programs/microvirus/gompertz_vs_malthus.R')
source('~/Dropbox/alberto.pascual/Dropbox/Research/Programs/microvirus/gompertz_vs_malthus.R')
plot(time,N_gomp1)
points(time,N_malt,pch=2,col="red")
points(time,N_gomp2,pch=3,col="green")
library(SpiecEasi)
library(phyloseq)
library(reshape2)
dirIn="../SparCC/input_data" # directory for the otu table
dirOut="../SparCC/output_data" # directory for output networks
thr=0.3 # thresholds
label="FunGroups_Time0" # an optional label to identify your data
setwd(dirIn)
library(SpiecEasi)
library(phyloseq)
library(reshape2)
dirIn="SparCC/input_data" # directory for the otu table relative to the root dir of the repo
dirOut="SparCC/output_data" # directory for output networks relative to the root dir of the repo
thr=0.3 # thresholds
label="FunGroups_Time0" # an optional label to identify your data
this.dir=strsplit(rstudioapi::getActiveDocumentContext()$path, "/src/")[[1]][1] # root  dir of the repo
dirIn=paste(this.dir,dirIn,sep="/")
dirOut=paste(this.dir,dirOut,sep="/")
setwd(dirIn)
otu.in=read.table(fileOTU,row.names = 1,skip=1)
fileOTU="OTU_table_Damian.sp.csv" # name of the otu table
otu.in=read.csv(fileOTU,row.names = 1)#,skip=1)
head(otu.in)[1:5,1:5] # double check
fileOTU="composition_otu_matched.csv" # name of the otu table
this.dir=strsplit(rstudioapi::getActiveDocumentContext()$path, "/src/")[[1]][1] # root  dir of the repo
dirIn=paste(this.dir,dirIn,sep="/")
dirOut=paste(this.dir,dirOut,sep="/")
setwd(dirIn)
getwd()
otu.in=read.csv(fileOTU,row.names = 1)#,skip=1)
head(otu.in)[1:5,1:5] # double check
sparcc=sparcc(otu.in) # Compute the correlations and covariances
str(sparcc)
otu.in=t(otu.in) # to compute correlations between OTUs we transpose here
sparcc=sparcc(otu.in) # Compute the correlations and covariances
sparcc.cor=sparcc$Cor # get the correlations
colnames(sparcc.cor)=colnames(otu.in)
rownames(sparcc.cor)=colnames(otu.in)
setwd(dirOut)
thisdir
this.dir
dirOut
dirInRel="SparCC/input_data" # directory for the otu table relative to the root dir of the repo
dirOutRel="SparCC/output_data" # directory for output networks relative to the root dir of the repo
dirIn=paste(this.dir,dirInRel,sep="/")
dirOut=paste(this.dir,dirOutRel,sep="/")
setwd(dirOut)
fileOut=paste("BasisCor_SparCC",label,".txt",sep="")
write.table(sparcc.cor,file=fileOut)
fileOut=paste("BasisCor_SparCC",label,".txt",sep="")
write.table(sparcc.cor,file=fileOut)
sparccBoot=sparccboot(otu.in,R=3)
sparccBoot=sparccboot(otu.in,R=4,ncpus = 4)
sparccboot()
str(sparccBoot)
system.time(test=seq(1,10000))
system.time({test=seq(1,10000)})
system.time({test=seq(1,10000)})
system.time({sparccBoot=sparccboot(otu.in,R=4,ncpus = 2)}) # Each bootstrap is much longer tha
str(sparccBoot)
sparccPval=pval.sparccboot(sparccBoot) # retrieve empirical pvalues from bootstrapped distro
sparccPval$pvals
sparccBoot$data
str(sparccBoot$data)
head(sparccBoot$data)
head(sparccBoot$data)[1:5,1:5]
head(sparccBoot$statistic)[1:5,1:5]
str(sparccBoot)
head(sparccBoot$t)[1:2,1:10]
head(sparccBoot$t0)[1:10]
View(sparccBoot$t0)
as.matrix(sparccBoot$t0)
as.matrix(sparccBoot$t)[,1:7]
as.matrix(sparccPval)[,1:7]
as.matrix(sparccPval$pvals)[,1:7]
as.matrix(sparccPval$pvals)[1:7]
as.matrix(sparccBoot$t0)[,1:7]
as.matrix(sparccBoot$t0)1:7]
as.matrix(sparccBoot$t0)[1:7]
id.sig=which((abs(sparccPval$cors) > thr) & (sparccPval$pvals > pval0))
pval0=0.01 # pvalue to determine that a correlation is significant
id.sig=which((abs(sparccPval$cors) > thr) & (sparccPval$pvals > pval0))
id.sig=which((abs(sparccPval$cors) > thr) & (sparccPval$pvals < pval0))
diag(sparcc.cor) = 0
sparcc.cor[lower.tri(sparcc.cor)]=0
sparcc.graph=melt(sparcc.cor) # transform into a network
sparcc.graph.sig=sparcc.graph[id.sig,] # get just those significant
sparcc.graph.sig$type=matrix(data=NA,nrow=dim(sparcc.graph.sig)[1],ncol=1)
sparcc.graph.sig$type[which(sparcc.graph.sig$value>0)]=1
sparcc.graph.sig$type[which(sparcc.graph.sig$value<0)]=-1
fileOut=paste("Network_BasisCor_SparCC_GT",thr,"_pval",pval0,"_",label,".txt",sep="")
write.table(sparcc.graph.sig,file=fileOut,quote=FALSE,row.names = FALSE,sep="\t")
abs(sparccPval$cors)
sparccPval[,id.sig]
sparccPval[id.sig,]
sparccPval[1,2]
sparccPval$cors[id.sig]
sparccPval$pvals[id.sig]
sparcc.graph[which(abs(sparcc.graph$value) > 0.3),]
otu.in=t(otu.in) # to compute correlations between OTUs we transpose here
sparcc=sparcc(otu.in) # Compute the correlations and covariances
head(sparcc)
colnames(sparcc.cor)=colnames(otu.in)
sparcc.cor=sparcc$Cor # get the correlations
colnames(sparcc.cor)=colnames(otu.in)
rownames(sparcc.cor)=colnames(otu.in)
head(sparacc.cor)
head(sparcc.cor)
diag(sparcc.cor) = 0
sparcc.cor[lower.tri(sparcc.cor)]=0
sparcc.graph=melt(sparcc.cor) # transform into a network
sparcc.graph[which(abs(sparcc.graph$value) > 0.3),]
nboot=4 #999 # number of bootstraps used to address the confidence interval
ncpus=2 # number of cpus used in the parallelization
sparccBoot=sparccboot(otu.in,R=nboot,ncpus = ncpus)
sparccPval=pval.sparccboot(sparccBoot) # retrieve empirical pvalues from bootstrapped distro
diag(sparcc.cor) = 0
setwd(dirOut)
fileOut=paste("BasisCor_SparCC",label,".txt",sep="")
write.table(sparcc.cor,file=fileOut,quote = FALSE)
sparcc.cor[lower.tri(sparcc.cor)]=0
sparcc.graph=melt(sparcc.cor) # transform into long matrix
id.sig=which((abs(sparccPval$cors) > thr) & (sparccPval$pvals < pval0))
sparcc.graph.sig=sparcc.graph[id.sig,] # get just those significant
sparccPval$cors[id.sig[1:10]]
sparcc.graph.sig[1:10,]
sparccBoot
str(sparccBoot)
581*580/2
head(sparcc.graph)
dim(sparcc.graph)
581*581
plot(sparcc.graph$value)
sparcc.graph=data.frame()
for(i in 1:(dim(sparcc.cor)[1]-1)){
for(j in (i+1):dim(sparcc.cor)[1]){
df.tmp=as.data.frame(c(colnames(sparcc.cor)[i],colnames(sparcc.cor)[j],
sparcc.cor[i,j]))
sparcc.graph=rbind(sparcc.graph,df.tmp)
}
}
dim(sparcc.cor)
df.tmp
df.tmp=t(as.data.frame(c(colnames(sparcc.cor)[i],colnames(sparcc.cor)[j],
sparcc.cor[i,j])))
df.tmp
df.tmp=c(colnames(sparcc.cor)[i],colnames(sparcc.cor)[j],
sparcc.cor[i,j]))
df.tmp=c(colnames(sparcc.cor)[i],colnames(sparcc.cor)[j],
sparcc.cor[i,j])
df.tmp=as.matrix(df.tmp)
df.tmp=as.data.frame(t(df.tmp))
df.tmp
sparcc.graph=data.frame() # transform manually into long matrix
for(i in 1:(dim(sparcc.cor)[1]-1)){
for(j in (i+1):dim(sparcc.cor)[1]){
df.tmp=c(colnames(sparcc.cor)[i],colnames(sparcc.cor)[j],
sparcc.cor[i,j])
df.tmp=as.matrix(df.tmp)
df.tmp=as.data.frame(t(df.tmp))
sparcc.graph=rbind(sparcc.graph,df.tmp)
}
}
